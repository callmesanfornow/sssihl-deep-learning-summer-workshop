{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numeric Example of Backpropogation using NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(input, w1, b1, w2, b2):\n",
    "    z1 = np.dot(w1, input) + b1\n",
    "    a1 = sigmoid(z1)\n",
    "    z2 = np.dot(w2, a1) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "    return a1, a2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Calculate Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(a2, target_output):\n",
    "    loss = 0.5 * np.square(a2 - target_output)\n",
    "    return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(input, target_output, a1, a2, w2):\n",
    "    d_loss = a2 - target_output\n",
    "    d_z2 = d_loss * sigmoid_derivative(a2)\n",
    "    d_w2 = np.dot(d_z2.reshape(-1, 1), a1.reshape(1, -1))\n",
    "    d_b2 = d_z2\n",
    "    d_z1 = np.dot(w2.T, d_z2) * sigmoid_derivative(a1)\n",
    "    d_w1 = np.dot(d_z1.reshape(-1, 1), input.reshape(1, -1))\n",
    "    d_b1 = d_z1\n",
    "    return d_w1, d_b1, d_w2, d_b2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4: Update Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(w1, b1, w2, b2, d_w1, d_b1, d_w2, d_b2, learning_rate):\n",
    "    w1 -= learning_rate * d_w1\n",
    "    b1 -= learning_rate * d_b1\n",
    "    w2 -= learning_rate * d_w2\n",
    "    b2 -= learning_rate * d_b2\n",
    "    return w1, b1, w2, b2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Misc Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Activation Function and its Deravative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = np.array([0.9, 0.8])\n",
    "target_output = np.array([1.0])\n",
    "\n",
    "w1 = np.array([[0.2, 0.3], [0.4, 0.5], [0.6, 0.7]])\n",
    "b1 = np.array([0.1, 0.2, 0.3])\n",
    "\n",
    "w2 = np.array([[0.4, 0.5, 0.6]])\n",
    "b2 = np.array([0.4])\n",
    "\n",
    "learning_rate = 0.1\n",
    "epochs = 1000\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: [0.0168109]\n",
      "Epoch: 100, Loss: [0.00464662]\n",
      "Epoch: 200, Loss: [0.00202994]\n",
      "Epoch: 300, Loss: [0.00110683]\n",
      "Epoch: 400, Loss: [0.00068673]\n",
      "Epoch: 500, Loss: [0.00046356]\n",
      "Epoch: 600, Loss: [0.00033201]\n",
      "Epoch: 700, Loss: [0.00024846]\n",
      "Epoch: 800, Loss: [0.00019231]\n",
      "Epoch: 900, Loss: [0.0001529]\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    # Step 1: Forward Propagation\n",
    "    a1, a2 = forward_propagation(input, w1, b1, w2, b2)\n",
    "\n",
    "    # Step 2: Calculate Loss\n",
    "    loss = calculate_loss(a2, target_output)\n",
    "\n",
    "    # Step 3: Backpropagation\n",
    "    d_w1, d_b1, d_w2, d_b2 = backward_propagation(input, target_output, a1, a2, w2)\n",
    "\n",
    "    # Step 4: Update Weights\n",
    "    w1, b1, w2, b2 = update_weights(w1, b1, w2, b2, d_w1, d_b1, d_w2, d_b2, learning_rate)\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch: {epoch}, Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Output: [0.98422156]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Final Output: {a2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
